/*
 * OpenAI API
 *
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 *
 * API version: 2.0.0
 * Generated by: Swagger Codegen (https://github.com/swagger-api/swagger-codegen.git)
 */
package swagger

import (
	"bytes"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
)

const DefaultModel = "qwen1.5-chat"
const DefaultUrl = "http://172.21.44.125:8091/v1/chat/completions"

func CreateChatCompletion(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json; charset=UTF-8")
	w.WriteHeader(http.StatusOK)
	// 从查询参数中获取API密钥
	apiKey := r.URL.Query().Get("api_key")
	if apiKey == "" {
		//logError(w, "API key is required", http.StatusBadRequest)
		apiKey = "empty"
		//return
	}

	// 解析请求体
	var requestBody CreateChatCompletionRequest
	if err := json.NewDecoder(r.Body).Decode(&requestBody); err != nil {
		logError(w, "Error decoding request body: "+err.Error(), http.StatusBadRequest)
		return
	}

	// 构建请求体
	chatRequest := map[string]interface{}{
		"model": DefaultModel, // 请根据需要替换为正确的模型
		"messages": []map[string]string{
			{"role": "system", "content": "You are a helpful assistant."},
			{"role": "user", "content": requestBody.Messages[0].Content},
		},
	}
	requestBodyBytes, err := json.Marshal(chatRequest)
	if err != nil {
		logError(w, "Error encoding request body: "+err.Error(), http.StatusInternalServerError)
		return
	}

	// 构建HTTP请求
	req, err := http.NewRequest("POST", DefaultUrl, bytes.NewBuffer(requestBodyBytes))
	if err != nil {
		logError(w, "Error creating request: "+err.Error(), http.StatusInternalServerError)
		return
	}
	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", fmt.Sprintf("Bearer %s", apiKey))
	// 发送请求
	client := &http.Client{}
	resp, err := client.Do(req)
	if err != nil {
		logError(w, "Error sending request: "+err.Error(), http.StatusInternalServerError)
		return
	}
	defer resp.Body.Close()

	// 读取响应体
	respBody, err := io.ReadAll(resp.Body)
	if err != nil {
		logError(w, "Error reading response body: "+err.Error(), http.StatusInternalServerError)
		return
	}

	// 解析响应体
	var respData struct {
		Choices []struct {
			Message struct {
				Content string `json:"content"`
			} `json:"message"`
		} `json:"choices"`
	}
	if err := json.Unmarshal(respBody, &respData); err != nil {
		logError(w, "Error parsing response body: "+err.Error(), http.StatusInternalServerError)
		return
	}

	// 假设我们只关心最后一条消息
	if len(respData.Choices) > 0 {
		lastMessage := respData.Choices[len(respData.Choices)-1].Message.Content
		w.Header().Set("Content-Type", "application/json")
		json.NewEncoder(w).Encode(map[string]string{"response": lastMessage})
	} else {
		logError(w, "No response from OpenAI", http.StatusInternalServerError)
	}
}

// func setOptionalFields(request *openai.ChatCompletionRequest, body CreateChatCompletionRequest) {
// 	if body.Model != "" {
// 		request.Model = body.Model
// 	}
// 	if body.Temperature != 0 {
// 		request.Temperature = float32(body.Temperature)
// 	}
// 	if body.MaxTokens != 0 {
// 		request.MaxTokens = int(body.MaxTokens)
// 	}
// 	if body.TopP != 0 {
// 		request.TopP = float32(body.TopP)
// 	}
// 	if body.FrequencyPenalty != 0 {
// 		request.FrequencyPenalty = float32(body.FrequencyPenalty)
// 	}
// 	if body.PresencePenalty != 0 {
// 		request.PresencePenalty = float32(body.PresencePenalty)
// 	}
// }
